{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4dce86-66c7-4cd7-92ed-43717f216cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import time\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de47d3-d5c1-494d-9f86-d23d4e63cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test whether the file is downloading or not before procedinh\n",
    "def download_test(name, year, M, D, H, file):\n",
    "    # Initialize a few counter/temp variables\n",
    "    n = 0\n",
    "    x = 0\n",
    "    percent = 0\n",
    "    y = 0\n",
    "    z = 0\n",
    "    inp = ' '\n",
    "    \n",
    "    # Run this loop until it is broken under specific circumstances\n",
    "    while True:\n",
    "        # Attempt to run main function but prepare for errors\n",
    "        try:\n",
    "            # Parse the name of the file in the directory to its opendap URL\n",
    "            url = 'https://opendap' + name[4:19] + 'opendap' + name[23:]\n",
    "            # Gather info from the URL to find the file's size\n",
    "            info = requests.head(url)\n",
    "\n",
    "            # Perform the folloeing while the file in the directory is smaller than the URL file size\n",
    "            while os.path.getsize(name) != int(info.headers['Content-Length']):\n",
    "                \n",
    "                # Define the percent of the way downloaded the file is (diretory file size divided by URL file size)\n",
    "                percent = round(os.path.getsize(name)*100/int(info.headers['Content-Length']))\n",
    "                reprint()\n",
    "                \n",
    "                # Print the percentage the download is at\n",
    "                print(year, M, D, H,'- Downloading:',str(percent)+'%',end=\"\\r\")\n",
    "\n",
    "                # If the percent has remained unchanged for 30 seconds, stop process and wait for command\n",
    "                if x == percent and n == 30:\n",
    "                    # Input to continue process or save a temporary file\n",
    "                    inp = input('Application paused. File is not downloading. Press Enter to continue.')\n",
    "                    # Reset counter variable\n",
    "                    n = 0\n",
    "                    # Save temp file as to not lose progress\n",
    "                    if inp.lower() == 'save':\n",
    "                        temp_save(file)\n",
    "                        break\n",
    "\n",
    "                # If percent has not changed and 30 seconds have not passed, increase counter\n",
    "                elif x == percent:\n",
    "                    n += 1\n",
    "\n",
    "                # Set temp variable to percent downloaded to track whether the download has stopped\n",
    "                x = percent\n",
    "\n",
    "                # Wait 1 second between iterations\n",
    "                time.sleep(1)\n",
    "                \n",
    "            # In the case that no storage remains, stop and wait for user input\n",
    "            if shutil.disk_usage(os.path.expanduser('~')).free < 70000000:\n",
    "                # Continue only if a temp file has not yet been saved\n",
    "                if inp.lower() != 'save':\n",
    "                    # Prompt to continue or to save temp file\n",
    "                    inp = input('Disk is out of space. Clear issue then hit Enter to continue.')\n",
    "                    if inp.lower() == 'save':\n",
    "                        temp_save(file)\n",
    "                        break\n",
    "\n",
    "            break\n",
    "\n",
    "        # Do not stop program in the case a file cannot be found\n",
    "        except FileNotFoundError:\n",
    "            reprint()\n",
    "            print('File not found:',name,end='\\r')\n",
    "            # Wait 15 seconds between iterations and check 4 times before accepting the file will not be downloaded and moving on\n",
    "            time.sleep(15)\n",
    "            z += 1\n",
    "            if z >= 4:\n",
    "                break\n",
    "\n",
    "        # Do not stop the program in the case of a connection error\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            # Increase count everytime connection is not achieved\n",
    "            y += 1\n",
    "            \n",
    "            # Prompt user intervention of 5 minutes have passed without connection\n",
    "            if y == 20:\n",
    "                inp = input('Program lost connection. Press Enter to continue.')\n",
    "                y = 0\n",
    "                if inp.lower() == 'save':\n",
    "                    temp_save(file)\n",
    "                    break\n",
    "                    \n",
    "            # Pause for 15 seconds before retrying loop\n",
    "            else:\n",
    "                reprint()\n",
    "                print('Retrying connection.', end = '\\r')\n",
    "                time.sleep(15)\n",
    "            \n",
    "        # Do not stop program in the case that the URL file size cannot be sourced\n",
    "        except KeyError:\n",
    "            reprint()\n",
    "            print(year, M, D, H,'Content length could not be found.')\n",
    "            try: \n",
    "                while True:\n",
    "                    reprint()\n",
    "                    print(year, M, D, H,'- Downloading',end=\"\\r\")\n",
    "                    \n",
    "                    # Only allow the program to continue if the file size has stopped changing and is greater than 40MB\n",
    "                    if os.path.getsize(name) == x and os.path.getsize(name) > 40000000:\n",
    "                        break\n",
    "                        \n",
    "                    # Prompt user intervention if the file has stopped growing but is less than 40MB\n",
    "                    elif os.path.getsize(name) == x:\n",
    "                        inp = input('File size is small. Check to ensure this is correct and hit Enter to continue.')\n",
    "                        if inp.lower() == 'save':\n",
    "                            temp_save(file)\n",
    "                            break\n",
    "                            \n",
    "                    # If file is still growing, check size again and wait 5 seconds\n",
    "                    else:\n",
    "                        x = os.path.getsize(name)\n",
    "                        time.sleep(5)\n",
    "                        \n",
    "                    if inp.lower() == 'save':\n",
    "                        break\n",
    "                \n",
    "            # If the program cannot find the desired file\n",
    "            except FileNotFoundError:\n",
    "                reprint()\n",
    "                print('File not found:',name,end='\\r')\n",
    "                # Wait 15 seconds between iterations and check 4 times before accepting the file will not be downloaded and moving on\n",
    "                time.sleep(15)\n",
    "                z += 1\n",
    "                if z >= 4:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "            break\n",
    "                    \n",
    "# A function that simply clears the command line\n",
    "def reprint():\n",
    "    print(' '*500,end='\\r')\n",
    "    \n",
    "# A function that saves all months that have been fully downloaded\n",
    "def temp_save(file):\n",
    "    file = file.drop(labels = 'VZA',axis = 1)\n",
    "    file = xr.Dataset.from_dataframe(file)\n",
    "    if year+'_TEMP.nc' in os.listdir():\n",
    "        file = xr.merge([xr.open_dataset(year+'_TEMP.nc'),file])\n",
    "        os.remove(year+'_TEMP.nc')\n",
    "    file.to_netcdf(year+'_TEMP.nc')\n",
    "    input('Temp file saved, please end program.')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d6656-b89c-4da6-b8c1-96b644608ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Terminal\n",
    "#cd ~\n",
    "#USERNAME_ = <your username>\n",
    "#PASSWORD = <your password>\n",
    "#touch .netrc\n",
    "#echo \"machine urs.earthdata.nasa.gov login $USERNAME_ password $PASSWORD\" > .netrc\n",
    "#nano .netrc (check to ensure your password and username are correct)\n",
    "#chmod 0600 .netrc\n",
    "#touch .urs_cookies\n",
    "#navigate to your desired download folder: cd <path>\n",
    "#cat .netrc\n",
    "#Test by downloading a single file: wget --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --auth-no-challenge=on --keep-session-cookies --content-disposition <URL>\n",
    "#Download all files: wget --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --auth-no-challenge=on --keep-session-cookies --content-disposition --recursive --wait=.05 --no-parent --reject \"index.html*\" --execute robots=off -c <URL>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mute Pandas warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Prompt download year to use later\n",
    "year = input('What year would you like to download?')\n",
    "\n",
    "# Prompt start month just in case a temp file has been created\n",
    "month_s = input('What month would you like to start with? Enter numerical value.')\n",
    "month_s = int(month_s)\n",
    "\n",
    "VA = input('What viewing zenith angle would you like?')\n",
    "VA = float(VA)\n",
    "\n",
    "# Define parts of the path the files will be downloaded to (URL is a legacy name)\n",
    "url1 = 'asdc.larc.nasa.gov/data/CERES/SSF/NPP-FM5-VIIRS_Edition2A/' + year + '/'\n",
    "url2 = '/CER_SSF_NPP-FM5-VIIRS_Edition2A_200203.' + year\n",
    "\n",
    "# Initialize all variables\n",
    "skip_count = 0\n",
    "\n",
    "total = []\n",
    "\n",
    "time_ = np.array([])\n",
    "lon = np.array([])\n",
    "lat = np.array([])\n",
    "SWrad = np.array([])\n",
    "LWrad = np.array([])\n",
    "sza = np.array([])\n",
    "vza = np.array([])\n",
    "TOAincoming = np.array([])\n",
    "\n",
    "sw_day = np.array([])\n",
    "lat_day = np.array([])\n",
    "lon_day = np.array([])\n",
    "time_day = np.array([])\n",
    "sza_day = np.array([])\n",
    "\n",
    "# Loop through all desired months, every day, and every hour\n",
    "for M in range(month_s,13):\n",
    "    M =str(M)\n",
    "    for D in range(1,32):\n",
    "        D=str(D)\n",
    "        for H in range(24):\n",
    "            H=str(H)\n",
    "            while len(D)<2:\n",
    "                D = '0'+D\n",
    "            while len(H)<2:\n",
    "                H = '0'+H\n",
    "            while len(M)<2:\n",
    "                M = '0'+M\n",
    "            \n",
    "            # Do nothing in the case the month-day combination does not exist\n",
    "            if ((int(M)==2 and int(D)>28) and (int(year)%4 != 0)) or ((int(M)==2) and (int(D)>29)) or (((int(M)==4) or (int(M)==6) or (int(M)==9) or (int(M)==11)) and (int(D)>30)):\n",
    "                None\n",
    "            else:\n",
    "                # Check if the file is being downloaded before moving on\n",
    "                download_test(url1+M+url2+M+D+H+'.nc', year, M, D, H, total)\n",
    "                \n",
    "                # Attemp to open file and parse data\n",
    "                try:\n",
    "                    # Open file associated with current M-D-H combinations\n",
    "                    file = nc.Dataset(url1+M+url2+M+D+H+'.nc')\n",
    "                    \n",
    "                    # Retrieve desired variables\n",
    "                    time_ = np.append(time_,np.array(file.groups['Time_and_Position'].variables['julian_observation_time'][:]))\n",
    "                    lon = np.append(lon,np.array(file.groups['Time_and_Position'].variables['instrument_fov_longitude'][:]))\n",
    "                    lat = np.append(lat,np.array(file.groups['Time_and_Position'].variables['instrument_fov_latitude'][:]))\n",
    "                    SWrad = np.append(SWrad,np.array(file.groups['Unfiltered_Radiances'].variables['shortwave_radiance'][:]))\n",
    "                    LWrad = np.append(LWrad,np.array(file.groups['Unfiltered_Radiances'].variables['longwave_radiance'][:]))\n",
    "                    sza = np.append(sza,np.array(file.groups['Viewing_Angles'].variables['solar_zenith_angle'][:]))\n",
    "                    vza = np.append(vza,np.array(file.groups['Viewing_Angles'].variables['view_zenith_angle'][:]))\n",
    "                    TOAincoming = np.append(TOAincoming,np.array(file.groups['TOA_and_Surface_Fluxes'].variables['toa_incoming_solar_radiation'][:]))\n",
    "                    \n",
    "                    # Delete file variabel for storage and delete actual file for storage\n",
    "                    file.close()\n",
    "                    del file\n",
    "                    os.remove(url1+M+url2+M+D+H+'.nc')\n",
    "                    \n",
    "                    # Parse all variables to viewing zenith angle less than .15\n",
    "                    time_ = time_[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    lon = lon[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    lat = lat[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    SWrad = SWrad[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    LWrad = LWrad[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    sza = sza[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    TOAincoming = TOAincoming[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    vza = vza[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    \n",
    "                    # Print the M-D-H combo of the file most recently completed\n",
    "                    reprint()\n",
    "                    print(year,M,D,H)\n",
    "                    # Reset skip counter due to successful download\n",
    "                    skip_count = 0\n",
    "                    \n",
    "                # Do not stop program if file does not exist\n",
    "                except FileNotFoundError:\n",
    "                    # Wait 5 seconds and try previous process again\n",
    "                    time.sleep(5)\n",
    "                    try:\n",
    "                        reprint()\n",
    "                        print('Cannot find', year, M, D, H+'.',end='\\r')\n",
    "                        download_test(url1+M+url2+M+D+H+'.nc',year,M,D,H,total)\n",
    "                        \n",
    "                        file = nc.Dataset(url1+M+url2+M+D+H+'.nc')\n",
    "                        \n",
    "                        time_ = np.append(time_,np.array(file.groups['Time_and_Position'].variables['julian_observation_time'][:]))\n",
    "                        lon = np.append(lon,np.array(file.groups['Time_and_Position'].variables['instrument_fov_longitude'][:]))\n",
    "                        lat = np.append(lat,np.array(file.groups['Time_and_Position'].variables['instrument_fov_latitude'][:]))\n",
    "                        SWrad = np.append(SWrad,np.array(file.groups['Unfiltered_Radiances'].variables['shortwave_radiance'][:]))\n",
    "                        LWrad = np.append(LWrad,np.array(file.groups['Unfiltered_Radiances'].variables['longwave_radiance'][:]))\n",
    "                        sza = np.append(sza,np.array(file.groups['Viewing_Angles'].variables['solar_zenith_angle'][:]))\n",
    "                        vza = np.append(vza,np.array(file.groups['Viewing_Angles'].variables['view_zenith_angle'][:]))\n",
    "                        TOAincoming = np.append(TOAincoming,np.array(file.groups['TOA_and_Surface_Fluxes'].variables['toa_incoming_solar_radiation'][:]))\n",
    "                    \n",
    "                        file.close()\n",
    "                        del file\n",
    "                        os.remove(url1+M+url2+M+D+H+'.nc')\n",
    "                        \n",
    "                        time_ = time_[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        lon = lon[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        lat = lat[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        SWrad = SWrad[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        LWrad = LWrad[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        sza = sza[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        TOAincoming = TOAincoming[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        vza = vza[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                        \n",
    "                    # If file still does not exist, simply skip it\n",
    "                    except FileNotFoundError:\n",
    "                        reprint()\n",
    "                        print('Skipping', year,M,D,H+'.')\n",
    "                        # Determine how many files have been skipped in a row\n",
    "                        if skip_count >= 5:\n",
    "                            # If 5 files have been skippes, call for user interaction and allow the chance to save progress\n",
    "                            skip_count = 0\n",
    "                            inp = input('Five files have been skipped in a row. Ensure this is correct then hit Enter.')\n",
    "                            if inp.lower() == 'save':\n",
    "                                temp_save(total)\n",
    "                        # If less than 5 files have been skipped, add to the counter\n",
    "                        else:\n",
    "                            skip_count += 1\n",
    "                        \n",
    "                # In the case that a downloaded file cannot be opened, reattempt\n",
    "                except OSError:\n",
    "                    reprint()\n",
    "                    print('Reattempting', year,M,D,H+'.')\n",
    "                    \n",
    "                    # Delete current iteration of file download\n",
    "                    os.remove(url1+M+url2+M+D+H+'.nc')\n",
    "                    \n",
    "                    # Define opendap URL to donwload from\n",
    "                    url = 'https://opendap.larc.nasa.gov/opendap/CERES/SSF/NPP-FM5-VIIRS_Edition2A/'+year+'/'+M+url2+M+D+H+'.nc'\n",
    "                    \n",
    "                    # Download file\n",
    "                    urllib.request.urlretrieve(url,'/Users/atocreu/Desktop/REU/'+year+M+D+H+'.nc')\n",
    "                    \n",
    "                    # Begin normal process\n",
    "                    file = nc.Dataset(year+M+D+H+'.nc')\n",
    "                    \n",
    "                    time_ = np.append(time_,np.array(file.groups['Time_and_Position'].variables['julian_observation_time'][:]))\n",
    "                    lon = np.append(lon,np.array(file.groups['Time_and_Position'].variables['instrument_fov_longitude'][:]))\n",
    "                    lat = np.append(lat,np.array(file.groups['Time_and_Position'].variables['instrument_fov_latitude'][:]))\n",
    "                    SWrad = np.append(SWrad,np.array(file.groups['Unfiltered_Radiances'].variables['shortwave_radiance'][:]))\n",
    "                    LWrad = np.append(LWrad,np.array(file.groups['Unfiltered_Radiances'].variables['longwave_radiance'][:]))\n",
    "                    sza = np.append(sza,np.array(file.groups['Viewing_Angles'].variables['solar_zenith_angle'][:]))\n",
    "                    vza = np.append(vza,np.array(file.groups['Viewing_Angles'].variables['view_zenith_angle'][:]))\n",
    "                    TOAincoming = np.append(TOAincoming,np.array(file.groups['TOA_and_Surface_Fluxes'].variables['toa_incoming_solar_radiation'][:]))\n",
    "                    \n",
    "                    file.close()\n",
    "                    del file\n",
    "                    os.remove(year+M+D+H+'.nc')\n",
    "                        \n",
    "                    time_ = time_[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    lon = lon[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    lat = lat[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    SWrad = SWrad[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    LWrad = LWrad[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    sza = sza[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    TOAincoming = TOAincoming[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    vza = vza[np.where((vza<(VA+.15))&(vza>(VA-.15)))]\n",
    "                    \n",
    "                    print(year,M,D,H,'reattempt successful.')\n",
    "                    \n",
    "                    \n",
    "    # At the end of the month announce that the month has finished and must be organized\n",
    "    print('Compiling data for',year,M)\n",
    "\n",
    "    # Add all retrieved variables to a pandas data fram\n",
    "    data = pd.DataFrame(data={\n",
    "        'time':time_,\n",
    "        'lon':lon,\n",
    "        'lat':lat,\n",
    "        'SWrad':SWrad,\n",
    "        'LWrad':LWrad,\n",
    "        'SZA':sza,\n",
    "        'VZA':vza,\n",
    "        'TOA_in':TOAincoming\n",
    "    })\n",
    "    \n",
    "    # Clear all variables for next month\n",
    "    time_ = np.array([])\n",
    "    lon = np.array([])\n",
    "    lat = np.array([])\n",
    "    SWrad = np.array([])\n",
    "    LWrad = np.array([])\n",
    "    sza = np.array([])\n",
    "    vza = np.array([])\n",
    "    TOAincoming = np.array([])\n",
    "    \n",
    "    # Set lon values to correct orientation, turn Julian datetime into normal time, replace bad values with NaN\n",
    "    data.lon = (data.lon+180)%360 - 180\n",
    "    data.time = pd.to_datetime(data.time,origin='julian',unit='D')\n",
    "    data.LWrad[data.LWrad > 2e+38] = np.NaN   \n",
    "    data.SWrad[data.SWrad > 2e+38] = np.NaN     \n",
    "    data.TOA_in[data.TOA_in > 2e+38] = 0\n",
    "    \n",
    "    # Iterate through all indexes in new dataframe\n",
    "    for i in range(len(data.time)):\n",
    "        # When i is divisible by 100, print the percent of the way through the indexing the loop is\n",
    "        if i % 100 == 0:\n",
    "            reprint()\n",
    "            print(str(round(100*i/len(data.time)))+'%',end=\"\\r\")\n",
    "\n",
    "        # Only acvept values that are not NAN. Also, round to the nearest lat and lon for averaging\n",
    "        if not (math.isnan(data.lat.iloc[i]) or math.isnan(data.lon.iloc[i])):\n",
    "            data.lon[i] = round(data.lon.iloc[i])\n",
    "            data.lat[i] = round(data.lat.iloc[i])\n",
    "\n",
    "        # Attempt to set the time index to stop at the day variable\n",
    "        try:\n",
    "            data.time[i] = datetime.datetime(data.time[i].year,data.time[i].month,data.time[i].day)\n",
    "        # If the value is not a time (NaT), simply use the previous time\n",
    "        except TypeError:\n",
    "            data.time[i] = datetime.datetime(data.time[i-1].year,data.time[i-1].month,data.time[i-1].day)\n",
    "            \n",
    "    # Gather variables for only the day time\n",
    "    sw_day = data.SWrad[data.SZA < 90]\n",
    "    lat_day = data.lat[data.SZA < 90]\n",
    "    lon_day = data.lon[data.SZA < 90]\n",
    "    time_day = data.time[data.SZA < 90]\n",
    "    sza_day = data.SZA[data.SZA < 90]\n",
    "    \n",
    "    \n",
    "    # Append these day variables to a new Pandas dataframe        \n",
    "    data_day = pd.DataFrame(data={\n",
    "        'time':time_day,\n",
    "        'lon':lon_day,\n",
    "        'lat':lat_day,\n",
    "        'SWrad_day':sw_day,\n",
    "        'SZA_day':sza_day\n",
    "    })\n",
    "    \n",
    "    # Clear the variables\n",
    "    sw_day = np.array([])\n",
    "    lat_day = np.array([])\n",
    "    lon_day = np.array([])\n",
    "    time_day = np.array([])\n",
    "    sza_day = np.array([])\n",
    "\n",
    "\n",
    "    # Turn both dataframes into multi-index dataframes with time, lat, lon being the indices\n",
    "    # Average all points of data that have the same three indices\n",
    "    \n",
    "    data.set_index(['time','lat','lon'],inplace=True)\n",
    "\n",
    "    data = data.groupby(level=data.index.names).mean()\n",
    "    \n",
    "    data_day.set_index(['time','lat','lon'],inplace=True)\n",
    "\n",
    "    data_day = data_day.groupby(level=data_day.index.names).mean()\n",
    "    \n",
    "    # Join the daytime values to the main dataframe and then delete it\n",
    "    data = data.join(data_day)\n",
    "    \n",
    "    del data_day\n",
    "    \n",
    "    # If the current month iteration is equal to the starting month, call it the dataframe total so that it may be appended to\n",
    "    if int(M) == month_s:\n",
    "        total = data\n",
    "        \n",
    "    # If the current month is not the starting month, append this months data to total\n",
    "    else:\n",
    "        total = pd.concat([total,data])\n",
    "        \n",
    "    # del data so that it may be reused\n",
    "    del data\n",
    "    \n",
    "\n",
    "    \n",
    "# Delete the viewing zenith angle column because it is no longer needed\n",
    "total = total.drop(labels = 'VZA',axis = 1)\n",
    "# Turn the dataframe into an xarray dataset because it is better suited to multiple coordinates\n",
    "total = xr.Dataset.from_dataframe(total)\n",
    "# Test if temp file was saved and combine into year long file if it was\n",
    "if year+'_TEMP.nc' in os.listdir():\n",
    "    total = xr.merge([xr.open_dataset(year+'_TEMP.nc'),total])\n",
    "    os.remove(year+'_TEMP.nc')\n",
    "# Save the dataset to a netcdf file\n",
    "total.to_netcdf(year+'_VZA_'+str(VA)+'_ERB.nc')\n",
    "\n",
    "reprint()\n",
    "print('DONE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo] *",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
